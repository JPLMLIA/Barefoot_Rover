{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, subprocess, sys\n",
    "sys.path.append('/home/phorton/Barefoot_Rover/src/ML')\n",
    "import numpy as np\n",
    "import tools_pg as tools\n",
    "import plots_pg as plots\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import peak_local_max\n",
    "from sklearn.neighbors import KDTree\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from ipywidgets import interact, Layout, IntSlider\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load up all the files that do not contain a rock positions file that are from the rock directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/data/MLIA_active_data/data_barefoot/'\n",
    "subfolders = ['train/rock_detection','data_Interns']\n",
    "files = np.hstack([glob.glob(datadir + a + '/*rock-*/') for a in subfolders])\n",
    "plotmaindir = datadir + 'train/' \n",
    "complete_mask = np.array([len(glob.glob(file + \"/rock_positions_*\")) == 1 for file in files])\n",
    "files = np.sort(files[~complete_mask])\n",
    "processing = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fix any errors with the date format. Also some files are missing photos so we remove them from our process list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_files = []\n",
    "# Fixes all image file names\n",
    "for file in files:\n",
    "    fname = file.split('/')[-2].split('_')\n",
    "    ftype = '_'.join([fname[a] for a in [1,3, 5, 9, 13, 15]])\n",
    "    jpgs = glob.glob(file +'/*[0-9]/*.jpg')\n",
    "    if len(jpgs) > 0:\n",
    "        jpg_time = np.hstack([a.split('/')[-1].split('.')[0] for a in jpgs])\n",
    "        for j in range(len(jpg_time)):\n",
    "            name = jpg_time[j].split('_')[-1]\n",
    "            if len(name) < 6:\n",
    "                new_name = ''.join([name, ''.join(['0']* (6 - len(name)))])\n",
    "                name_split = jpgs[j].split('_')\n",
    "                name_split[-1] = new_name + '.jpg'\n",
    "                jpg_new = '_'.join(name_split)\n",
    "                os.rename(jpgs[j], jpg_new)\n",
    "    else:\n",
    "        bad_files.append(file)\n",
    "        print(\"WARNING:\", file, \"is missing photos... removing!\")\n",
    "for file in bad_files:\n",
    "    files = np.delete(files,np.where(files == file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a funciton to load the image if we want to use the interactive route to identify files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(i):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    global current_file\n",
    "    current_file = jpgs[i]\n",
    "    plt.imshow(mpimg.imread(current_file))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have everything loaded we start from here. This will load all the image names for a given processing ID (starting at 0 and incrementing after every process). Once the images are all loaded we need to identify the interesting bits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = files[processing]\n",
    "print(f'Processing {processing} of {len(files)}: {file}')\n",
    "fname = file.split('/')[-2].split('_')\n",
    "ftype = '_'.join([fname[a] for a in [1,3, 5, 9, 13, 15]])\n",
    "jpgs = glob.glob(file +'/*[0-9]/*.jpg')\n",
    "jpgs = np.sort(jpgs)\n",
    "jpg_time = np.hstack([a.split('/')[-1].split('.')[0] for a in jpgs])\n",
    "jpg_time = np.sort(jpg_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the interesting bits we can either use this function to scroll through the images or use your computers image viewer to view the images on the server. \n",
    "\n",
    "Using the widget below you can scroll through the images. When you are on an image of interest use the next cell to print out the current file name and place it in the rocks\n",
    "array below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(load_img,i=widgets.IntSlider(min=0,max=len(jpgs)-1,step=1,layout=Layout(width=\"1000px\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rocks array can be used to identify start, stop, and depth of points of interest. It is formatted like so:\n",
    "\n",
    "```\n",
    "rocks = [\n",
    "    (start_name, stop_name, depth),\n",
    "    (start_name, stop_name, depth),\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "The names of the start and stop can be obtained from the above widget or from your computers file browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocks = [\n",
    "    (\"start\",\"stop\",0.0),\n",
    "    (\"start\",\"stop\",0.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we create a text file with the new information. Check if the indicies of the start and end point for each rock make sense. If they do run the proceeding cell to save the file to the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = np.column_stack([jpg_time] + \n",
    "                       [np.repeat(0, len(jpg_time))]*(len(rocks) + 1) + \n",
    "                       [np.repeat(0.0, len(jpg_time))])\n",
    "for i, (start, end, depth) in enumerate(rocks):\n",
    "    i1 = int(np.where(text[:,0] == start)[0])\n",
    "    i2 = int(np.where(text[:,0] == end)[0])\n",
    "    print(i1,i2)\n",
    "    text[i1:i2,i+1] = '1'\n",
    "    text[i1:i2,-1] = str(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(file + 'rock_positions_' + ftype + '.txt', text, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increment the processing ID and go back to the cell that starts with `file=files[processing]` to start labeling the next rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
